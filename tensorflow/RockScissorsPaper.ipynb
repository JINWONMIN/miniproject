{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a4ba33",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 and Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c87333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"import\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f51d49",
   "metadata": {},
   "source": [
    ">  Change the image of scissors 224 * 224 to 28 * 28 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4caeee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  images to be resized.\n",
      "0  images resized.\n",
      "scissors resize completion\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "    images = glob.glob(img_path + \" /*.jpg\")\n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "    \n",
    "    # Save 28 * 28 sizes with using for statemne all file\n",
    "    target_size = (28, 28)\n",
    "    for img in images:\n",
    "        old_img = image.open(img)\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "        \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# scissors images stored '*.jpg' at project directory read and save\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/tensorflow/MiniProject/rock_scissor_paper/train_data_1/scissor/scissor_1\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"scissors resize completion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aae767",
   "metadata": {},
   "source": [
    "> Change the image of rock 224 * 224 to 28 * 28 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027dbacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # Save 28 * 28 sizes with using for statemne all file.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "    \n",
    "# rock images stored '*.jpg' at project directory read and save\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/tensorflow/MiniProject/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"rock resize completion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9e647",
   "metadata": {},
   "source": [
    "> Change the image of paper 224 * 224 to 28 * 28 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1578cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # Save 28 * 28 sizes with using for statemne all file.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "    \n",
    "# paper images stored '*.jpg' at project directory read and save\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/tensorflow/MiniProject/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"paper resize completion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1087b886",
   "metadata": {},
   "source": [
    "> making a Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d89d1627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/tensorflow/MiniProject/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d81610d",
   "metadata": {},
   "source": [
    "> os를 이용한 file name rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e3dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.getenv(\"HOME\") + \"/aiffel/tensorflow/MiniProject/rock_scissor_paper/scissor\"\n",
    "file_names = os.listdir(file_path)\n",
    "file_names\n",
    "\n",
    "i = 200\n",
    "for name in file_names:\n",
    "    src = os.path.join(file_path, name)\n",
    "    dst = str(i) + '.jpg'\n",
    "    dst = os.path.join(file_path, dst)\n",
    "    os.rename(src, dst)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320e751",
   "metadata": {},
   "source": [
    "> 이미지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20a264be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5593e7",
   "metadata": {},
   "source": [
    "> 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7959b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                51264     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 56,547\n",
      "Trainable params: 56,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9382f6aa",
   "metadata": {},
   "source": [
    "> 네트워크 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e4787b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9900\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9933\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9967\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7887d92940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569df147",
   "metadata": {},
   "source": [
    "> test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75406d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실험데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def load_data_test(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissors/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"실험데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/tensorflow/MiniProject/rock_scissor_paper/test_data\"\n",
    "(x_test, y_test)=load_data_test(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f2c14d",
   "metadata": {},
   "source": [
    "> evaluate api 이용해서 훈련시킨 model로 test_accuracy를 측정 (loss, acy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "765f5d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 9.0016 - accuracy: 0.3433\n",
      "test_loss: 9.001640319824219 \n",
      "test_accuracy: 0.34333333373069763\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb0182",
   "metadata": {},
   "source": [
    "> 하이퍼 파라미터 값 변경 후 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df419759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                204864    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 280,707\n",
      "Trainable params: 280,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598997af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "57/57 [==============================] - 3s 5ms/step - loss: 0.9587 - accuracy: 0.5478\n",
      "Epoch 2/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8578\n",
      "Epoch 3/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9606\n",
      "Epoch 4/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9833\n",
      "Epoch 5/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9933\n",
      "Epoch 6/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9950\n",
      "Epoch 7/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9967\n",
      "Epoch 8/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9994\n",
      "Epoch 9/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9994\n",
      "Epoch 10/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f78840f18e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb1911",
   "metadata": {},
   "source": [
    "test_data 재측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0ae12a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 11.4321 - accuracy: 0.3400\n",
      "test_loss: 11.432121276855469 \n",
      "test_accuracy: 0.3400000035762787\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310d93af",
   "metadata": {},
   "source": [
    "파라미터 값 조정으로 인식률 향상에 어려움이 있어 <br/>\n",
    "<br/>\n",
    "모델을 학습시킬 데이터량을 증가하였음. 각 클래스 별 600개씩 1800개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cb848f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1800 입니다.\n",
      "x_train shape: (1800, 28, 28, 3)\n",
      "y_train shape: (1800,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def load_data3(img_path, number_of_data=1800):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor_1/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/scissor_2/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/scissor_3/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/scissors_4/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/rock_1/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/rock_2/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/rock_3/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "        \n",
    "    for file in glob.iglob(img_path+'/rock_4/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1 \n",
    "        \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    for file in glob.iglob(img_path+'/paper_1/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "image_dir_path4 = os.getenv(\"HOME\") + \"/aiffel/tensorflow/MiniProject/rock_scissor_paper/train_data_1\"\n",
    "(x_train, y_train)=load_data3(image_dir_path4)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22489af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                51264     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 56,547\n",
      "Trainable params: 56,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67232944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.0833 - accuracy: 0.6606\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.9011\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9672\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9872\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9950\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9983\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9983\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9983\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9994\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9994\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7887de8fa0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45090d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 15.3495 - accuracy: 0.3333\n",
      "test_loss: 15.349529266357422 \n",
      "test_accuracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d621ebe",
   "metadata": {},
   "source": [
    "### 회고\n",
    "\n",
    "양질의 데이터로 모델을 학습시켜야 정확도가 높아진다는 걸 확인할 수 있었음.<br/>\n",
    "질이 떨어지는 데이터로 학습시킨 후 파라미터 값 및 학습 데이터의 양을 늘린다고 해도 정확도의 상승을 기대하긴 어려움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7310e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
